services:
  # --- Application Services ---
  db:
    image: pgvector/pgvector:pg16
    container_name: noda_turbo_postgres
    restart: always
    ports: [ "${POSTGRES_PORT}:5432" ]
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes: [ "db_data:/var/lib/postgresql/data" ]
    networks:
      - noda_network # Assign to our custom network
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: noda_turbo_redis
    restart: always
    ports: [ "6379:6379" ]
    volumes: [ "redis_data:/data" ]
    networks:
      - noda_network # Assign to our custom network
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 5

  ingestor:
    build:
      context: .
      dockerfile: ./apps/data-ingestion-service/Dockerfile
    container_name: noda_turbo_ingestor
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
    restart: on-failure
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    volumes: [ "./apps/data-ingestion-service/data:/app/apps/data-ingestion-service/data" ]
    networks:
      - noda_network # Assign to our custom network
  graphql-api:
    build:
      context: .
      dockerfile: ./apps/graphql-api/Dockerfile
    container_name: noda_turbo_graphql_api
    restart: always
    ports: [ "4000:4000" ]
    env_file:
      - .env
    depends_on:
      db: { condition: service_healthy }
      redis: { condition: service_healthy }
      llm-service: { condition: service_healthy } # MODIFIED: This is now active
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
      REDIS_URL: "redis://redis:6379"
      LLM_SERVICE_URL: "http://llm-service:5001" # This URL is correct
      PORT: 4000
    networks:
      - noda_network # Assign to our custom network
  llm-service:
    # MODIFIED: Moved llm-service before graphql-api for clarity
    build:
      context: .
      dockerfile: ./apps/llm-service/Dockerfile
    container_name: noda_turbo_llm_service
    restart: always
    ports:
      - "5001:5001"
    env_file:
      - .env
    depends_on:
      db: { condition: service_healthy }
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      PORT: 5001
    networks:
      - noda_network # Assign to our custom network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:5001/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  docs:
    build:
      context: .
      dockerfile: ./apps/docs/Dockerfile
    container_name: noda_turbo_docs
    restart: always
    ports: [ "3002:3000" ]
    volumes: [ "./apps/docs:/book" ]
    networks:
      - noda_network # Assign to our custom network

# Named volumes for persistent data storage
volumes:
  db_data:
  redis_data:

    # Define the network for all services to communicate
networks:
  noda_network:
    # MODIFIED: The network name matches what's used above
    name: noda_network
